{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import r2_score\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "mingw_path = 'C:\\\\Program Files\\\\mingw-w64\\\\x86_64-8.1.0-posix-seh-rt_v6-rev0\\\\mingw64\\\\bin'\n",
    "os.environ['PATH'] = mingw_path + ';' + os.environ['PATH']\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get training and testing data\n",
    "\n",
    "def get_data(train_data_path='data/train.csv', test_data_path='data/test.csv'):\n",
    "    print(\"Grabbing train data from '{}'...\".format(train_data_path))\n",
    "    print(\"Grabbing test data from '{}'...\".format(test_data_path))\n",
    "    train_data = pd.read_csv(train_data_path)\n",
    "    test_data = pd.read_csv(test_data_path)\n",
    "    print(\"Data successfully loaded.\")\n",
    "    return train_data, test_data\n",
    "\n",
    "# returns train & test dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to remove any columns with >50% null values\n",
    "\n",
    "def remove_null_columns(df, threshold=0.5, return_removed_cols=False):\n",
    "    print(\"Removing columns that are >{}% null...\".format(round(threshold*100)))\n",
    "    percent_null = [sum(df[col].isnull()/len(df[col])) for col in df]\n",
    "    null_series = pd.Series(percent_null)\n",
    "    null_series.set_axis(df.columns, inplace=True)\n",
    "    null_series.sort_values(ascending=False, inplace=True)\n",
    "    cols_to_remove = null_series[null_series > threshold].index\n",
    "    print(\"{} columns were removed.\".format(len(cols_to_remove)))\n",
    "    if not return_removed_cols:\n",
    "        return df.drop(columns=cols_to_remove, axis=1)\n",
    "    else:\n",
    "        return df.drop(columns=cols_to_remove, axis=1), cols_to_remove\n",
    "    \n",
    "# returns dataframe (minus removed null columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to return two lists of features:\n",
    "# (a) list of numerical features\n",
    "# (b) list of categorical features\n",
    "\n",
    "def get_feature_lists(df):\n",
    "    print(\"Obtaining feature column names...\")\n",
    "    numeric_cols = list(df.columns[df.dtypes != 'object'])\n",
    "    all_cols = list(df.columns)\n",
    "    false_numeric_cols = [\n",
    "        'MSSubClass',\n",
    "        'MoSold'\n",
    "    ]\n",
    "    non_feature_cols = [\n",
    "        'Id',\n",
    "        'SalePrice'\n",
    "    ]\n",
    "    \n",
    "    true_numeric_cols = [col for col in numeric_cols if (col not in false_numeric_cols and col not in non_feature_cols)]\n",
    "    categorical_cols = [col for col in all_cols if (col not in non_feature_cols and col not in true_numeric_cols)]\n",
    "    \n",
    "    print(\"{} numeric features obtained; {} categorical features obtained\".format(len(true_numeric_cols),\n",
    "                                                                                  len(categorical_cols)))\n",
    "            \n",
    "    return true_numeric_cols, categorical_cols\n",
    "\n",
    "# returns lists of num & cat columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to return two dataframes:\n",
    "# (a) dataframe of imputed numerical features (fill NaN values with mean)\n",
    "# (b) dataframe of imputed categorical features (fill NaN values with mode)\n",
    "# (c) generate dummy values for categorical fields\n",
    "\n",
    "def impute_features(df_numerical, df_categorical):\n",
    "    print(\"Imputing data...\")\n",
    "    imp_numerical = Imputer(strategy='mean')\n",
    "    df_numerical_imputed = pd.DataFrame(imp_numerical.fit_transform(df_numerical), \n",
    "                                        columns=df_numerical.columns, \n",
    "                                        index=df_numerical.index)\n",
    "    \n",
    "    df_categorical.fillna(value='missing', inplace=True)\n",
    "    reclassify_categories(df_categorical)\n",
    "    df_categorical_imputed = pd.get_dummies(df_categorical)\n",
    "    \n",
    "    print(\"Imputation complete.\\nThere are now {} numerical features and {} categorical features.\".format(len(df_numerical_imputed.columns),\n",
    "                                                                                                             len(df_categorical_imputed.columns)))\n",
    "        \n",
    "    return df_numerical_imputed, df_categorical_imputed\n",
    "\n",
    "# returns imputed num & cat dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to filter for only features present in both training and testing sets\n",
    "\n",
    "def prune_categorical_features(df_cat_train, df_cat_test):\n",
    "    cat_train = df_cat_train.columns\n",
    "    cat_test = df_cat_test.columns\n",
    "    cat_common = [feature for feature in cat_train if feature in cat_test]\n",
    "    return cat_common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineering functions:\n",
    "# change a year feature into an age feature\n",
    "\n",
    "def get_year_features():\n",
    "    return ['YrSold', 'GarageYrBlt', 'YearRemodAdd', 'YearBuilt']\n",
    "\n",
    "def calculate_age(year):\n",
    "    age = 2018 - year\n",
    "    return age\n",
    "\n",
    "def year_to_age(df):\n",
    "    print(\"Feature engineering: transforming years to time since...\")\n",
    "    year_features = get_year_features()\n",
    "    df[year_features] = df[year_features].copy().apply(calculate_age)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineering functions:\n",
    "# perform log transform on relevant numerical features\n",
    "\n",
    "def get_log_features():\n",
    "    return ['LotFrontage', 'LotArea', 'MasVnrArea', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF',\n",
    "            '1stFlrSF', '2ndFlrSF', 'LowQualFinSF', 'GrLivArea', 'GarageArea', 'WoodDeckSF', 'OpenPorchSF',\n",
    "            'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'MiscVal']\n",
    "\n",
    "def log_transform(x):\n",
    "    return np.log(x + 1)\n",
    "    \n",
    "def log_xform_features(df):\n",
    "    print(\"Feature engineering: log transform of relevant numerical features...\")\n",
    "    log_features = get_log_features()\n",
    "    df[log_features] = df[log_features].copy().apply(log_transform)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineering function:\n",
    "# normalize numerical data to scale between 0 and 1\n",
    "\n",
    "def normalize_numerical_features(df):\n",
    "    print(\"Feature engineering: normalizing numerical data to scale between 0 and 1...\")\n",
    "    scaler = MinMaxScaler()\n",
    "    df_transformed = scaler.fit_transform(df)\n",
    "    df_normalized = pd.DataFrame(df_transformed, columns=df.columns, index=df.index)\n",
    "    return df_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineering function:\n",
    "# create meta numerical features\n",
    "\n",
    "def build_meta_features(df):\n",
    "    df['overallScore'] = df['OverallQual'] * df['OverallCond'] + 1\n",
    "    df['BsmtIncompleteRatio'] = df['BsmtUnfSF'] / (df['BsmtFinSF1'] + df['BsmtFinSF2'] + 1)\n",
    "    df['HouseSFScore'] = (df['TotalBsmtSF'] + 1) * (df['1stFlrSF'] + df['2ndFlrSF'] + 1)\n",
    "    df['BathScore'] = (df['BsmtFullBath'] + df['BsmtHalfBath'] + df['FullBath'] + df['HalfBath']) ** 2\n",
    "    df['GarageScore'] = df['GarageCars'] * df['GarageArea'] + 1\n",
    "    df['PorchScore'] = (df['OpenPorchSF'] + 1) * (df['EnclosedPorch'] + 1) * (df['3SsnPorch'] + 1) * (df['ScreenPorch'] + 1)\n",
    "    df['ageScore'] = df['YearBuilt'] * df['YearRemodAdd'] + 1\n",
    "#     df['frontageRatio'] = df['LotFrontage'] / (df['LotArea'].apply(lambda x: np.sqrt(x)) + 1)\n",
    "#     df['liveAreaRatio'] = (df['GrLivArea'] + 1) / (df['LotArea'] + 1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to call all feature engineering functions\n",
    "def feature_engineering(df):\n",
    "    print(\"Starting feature engineering...\")\n",
    "    df = year_to_age(df)\n",
    "    df = build_meta_features(df)\n",
    "    df = log_xform_features(df)\n",
    "#     df = normalize_numerical_features(df)\n",
    "    print(\"Feature engineering complete.\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for feature engineering categorical values\n",
    "\n",
    "def rename_value(data, current, new):\n",
    "    data.replace(to_replace=current, value=new, inplace=True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for mapping categorical feature engineering\n",
    "\n",
    "def reclassify_categories(df):\n",
    "    \n",
    "    # MSSubClass\n",
    "    for val in [20, 30, 40, 120]:\n",
    "        rename_value(df['MSSubClass'], val, '1story')\n",
    "    for val in [45, 50, 150]:\n",
    "        rename_value(df['MSSubClass'], val, '1halfstory')\n",
    "    for val in [60, 70, 160, 190]:\n",
    "        rename_value(df['MSSubClass'], val, '2story')\n",
    "    for val in [80, 85, 90, 180]:\n",
    "        rename_value(df['MSSubClass'], val, 'splitOrDuplex')\n",
    "    rename_value(df, 75, '2halfstory')\n",
    "    \n",
    "    # MSZoning\n",
    "    for val in ['RH', 'RL', 'RP', 'RM', 'FV']:\n",
    "        rename_value(df['MSZoning'], val, 'Residential')\n",
    "    for val in ['I', 'C', 'A']:\n",
    "        rename_value(df['MSZoning'], val, 'Other')\n",
    "        \n",
    "    # LotShape\n",
    "    for val in ['IR1', 'IR2', 'IR3']:\n",
    "        rename_value(df['LotShape'], val, 'Irregular')\n",
    "    \n",
    "    # LotConfig\n",
    "    for val in ['FR2', 'FR3']:\n",
    "        rename_value(df['LotConfig'], val, 'Frontage')\n",
    "        \n",
    "    # LandSlope\n",
    "    for val in ['Mod', 'Sev']:\n",
    "        rename_value(df['LandSlope'], val, 'Sloped')\n",
    "    \n",
    "    # Condition1\n",
    "    for val in ['RRAn', 'RRNn', 'RRNe', 'RRAe']:\n",
    "        rename_value(df['Condition1'], val, 'Railroad')\n",
    "    for val in ['Artery', 'Feedr']:\n",
    "        rename_value(df['Condition1'], val, 'Adjacent')\n",
    "    for val in ['PosA', 'PosN']:\n",
    "        rename_value(df['Condition1'], val, 'Positive')\n",
    "        \n",
    "    # BldgType\n",
    "    for val in ['2FmCon', 'Duplx']:\n",
    "        rename_value(df, val, 'Half')\n",
    "    for val in ['TwnhsE', 'TwnhsE']:\n",
    "        rename_value(df, val, 'Townhouse')\n",
    "        \n",
    "    # HouseStyle\n",
    "    for val in ['1.5Fin', '2Story', '2.5Fin', '2.5Unf']:\n",
    "        rename_value(df['HouseStyle'], val, 'twoStory')\n",
    "    for val in ['1Story', '1.5Unf']:\n",
    "        rename_value(df['HouseStyle'], val, 'oneStory')\n",
    "    for val in ['SFoyer', 'SLvl']:\n",
    "        rename_value(df['HouseStyle'], val, 'Split')\n",
    "        \n",
    "    # RoofStyle\n",
    "    for val in ['Flat', 'Gambrel', 'Mansard', 'Shed']:\n",
    "        rename_value(df['RoofStyle'], val, 'Other')\n",
    "        \n",
    "    # Exterior1st\n",
    "    for val in ['AsbShng', 'CBlock', 'CemntBd', 'HdBoard',\n",
    "                'ImStucc', 'Plywood']:\n",
    "        rename_value(df['Exterior1st'], val, 'Low')\n",
    "    for val in ['AsphShn', 'BrkComm', 'BrkFace', 'MetalSd',\n",
    "                'PreCast', 'Stucco', 'VinylSd']:\n",
    "        rename_value(df['Exterior1st'], val, 'Medium')\n",
    "    for val in ['Stone', 'Wd Sdng', 'WdShing']:\n",
    "        rename_value(df['Exterior1st'], val, 'High')\n",
    "    \n",
    "    # Exterior2nd\n",
    "    for val in ['AsbShng', 'CBlock', 'CemntBd', 'HdBoard',\n",
    "                'ImStucc', 'Plywood']:\n",
    "        rename_value(df['Exterior2nd'], val, 'Low')\n",
    "    for val in ['AsphShn', 'BrkComm', 'BrkFace', 'MetalSd',\n",
    "                'PreCast', 'Stucco', 'VinylSd']:\n",
    "        rename_value(df['Exterior2nd'], val, 'Medium')\n",
    "    for val in ['Stone', 'Wd Sdng', 'WdShing']:\n",
    "        rename_value(df['Exterior2nd'], val, 'High')\n",
    "        \n",
    "    # ExterCond\n",
    "    for val in ['Ex', 'Gd']:\n",
    "        rename_value(df['ExterCond'], val, 'High')\n",
    "    for val in ['Fa', 'Po']:\n",
    "        rename_value(df['ExterCond'], val, 'Low')\n",
    "    \n",
    "    # Foundation\n",
    "    for val in ['BrkTil', 'Stone']:\n",
    "        rename_value(df['Foundation'], val, 'High')\n",
    "    for val in ['Slab', 'Wood']:\n",
    "        rename_value(df['Foundation'], val, 'Medium')\n",
    "    for val in ['CBlock', 'PConc']:\n",
    "        rename_value(df['Foundation'], val, 'Low')\n",
    "        \n",
    "    # BsmtQual\n",
    "    for val in ['Ex', 'Gd']:\n",
    "        rename_value(df['BsmtQual'], val, 'High')\n",
    "    for val in ['Fa', 'Po', 'NA']:\n",
    "        rename_value(df['BsmtQual'], val, 'Low')\n",
    "        \n",
    "    # BsmtCond\n",
    "    for val in ['Ex', 'Gd']:\n",
    "        rename_value(df['BsmtCond'], val, 'High')\n",
    "    for val in ['Fa', 'Po', 'NA']:\n",
    "        rename_value(df['BsmtCond'], val, 'Low')\n",
    "        \n",
    "    #BsmtExposure\n",
    "    for val in ['Mn', 'No', 'NA']:\n",
    "        rename_value(df['BsmtExposure'], val, 'Low')\n",
    "        \n",
    "    #BsmtFinType2\n",
    "    for val in ['GLQ', 'ALQ']:\n",
    "        rename_value(df['BsmtFinType2'], val, 'High')\n",
    "    for val in ['BLQ', 'Rec', 'LwQ', 'NA']:\n",
    "        rename_value(df['BsmtFinType2'], val, 'Low')\n",
    "    \n",
    "    # HeatingQC\n",
    "    for val in ['Ex', 'Gd']:\n",
    "        rename_value(df['HeatingQC'], val, 'High')\n",
    "    for val in ['Fa', 'Po', 'NA']:\n",
    "        rename_value(df['HeatingQC'], val, 'Low')\n",
    "        \n",
    "    # Electrical\n",
    "    for val in ['SBrkr', 'FuseA']:\n",
    "        rename_value(df['Electrical'], val, 'Standard')\n",
    "    for val in ['FuseF', 'FuseP', 'Mix']:\n",
    "        rename_value(df['Electrical'], val, 'NonStandard')\n",
    "        \n",
    "    # KitchenQual\n",
    "    for val in ['Ex', 'Gd']:\n",
    "        rename_value(df['KitchenQual'], val, 'High')\n",
    "    for val in ['Fa', 'Po', 'NA']:\n",
    "        rename_value(df['KitchenQual'], val, 'Low')\n",
    "        \n",
    "    # Functional\n",
    "    for val in ['Min1', 'Min2', 'Mod', 'Maj1', 'Maj2', 'Sev', 'Sal']:\n",
    "        rename_value(df['Functional'], val, 'NonTyp')\n",
    "        \n",
    "    # FireplaceQu\n",
    "    for val in ['Ex', 'Gd']:\n",
    "        rename_value(df['FireplaceQu'], val, 'High')\n",
    "    for val in ['Fa', 'Po', 'NA']:\n",
    "        rename_value(df['FireplaceQu'], val, 'Low')\n",
    "        \n",
    "    # GarageType\n",
    "    for val in ['Attchd', 'Basment', 'BuiltIn', '2Types']:\n",
    "        rename_value(df['GarageType'], val, 'Attached')\n",
    "    for val in ['CarPort', 'Detchd', 'NA']:\n",
    "        rename_value(df['GarageType'], val, 'Detached')\n",
    "        \n",
    "    # GarageFinish\n",
    "    for val in ['Unf', 'RFn', 'NA']:\n",
    "        rename_value(df['GarageFinish'], val, 'Unfinished')\n",
    "        \n",
    "    # GarageQual\n",
    "    for val in ['Ex', 'Gd']:\n",
    "        rename_value(df['GarageQual'], val, 'High')\n",
    "    for val in ['Fa', 'Po', 'NA']:\n",
    "        rename_value(df['GarageQual'], val, 'Low')\n",
    "        \n",
    "    # PavedDrive\n",
    "    for val in ['P', 'N']:\n",
    "        rename_value(df['PavedDrive'], val, 'Unpaved')\n",
    "        \n",
    "    # Fence\n",
    "#     for val in ['GdPrv', 'GdWo']:\n",
    "#         rename_value(df['Fence'], val, 'High')\n",
    "#     for val in ['MnPrv', 'MnWw', 'NA']:\n",
    "#         rename_value(df['Fence'], val, 'Low')\n",
    "        \n",
    "    # MiscFeature\n",
    "#     for val in ['Elev', 'Gar2', 'Othr', 'Shed', 'TenC', 'NA']:\n",
    "#         rename_value(df['MiscFeature'], val, 'Yes')\n",
    "        \n",
    "    # MoSold\n",
    "    for val in [1, 2, 3, 10, 11, 12]:\n",
    "        rename_value(df['MoSold'], val, 'Off')\n",
    "    for val in [4, 5, 6, 7, 8, 9]:\n",
    "        rename_value(df['MoSold'], val, 'On')\n",
    "        \n",
    "    # SaleType\n",
    "    for val in ['CWD', 'VWD', 'COD', 'Con', 'ConLw', 'ConLI',\n",
    "                'ConLD', 'Oth']:\n",
    "        rename_value(df['SaleType'], val, 'Unconventional')\n",
    "\n",
    "    # SaleCondition\n",
    "    for val in ['Normal', 'Alloca']:\n",
    "        rename_value(df['SaleCondition'], val, 'NormalSale')\n",
    "    for val in ['Abnormal', 'AdjLand']:\n",
    "        rename_value(df['SaleCondition'], val, 'NonSale')\n",
    "    for val in ['Family', 'Partial']:\n",
    "        rename_value(df['SaleCondition'], val, 'LowerSale')\n",
    "        \n",
    "    # Neighborhood\n",
    "#     for val in ['Blmngtn', 'Blueste', 'BrDale', 'BrkSide', 'CollgCr', 'IDOTRR', 'MeadowV', 'Mitchel',\n",
    "#                 'NAmes', 'NPkVill', 'OldTown', 'Sawyer', 'SawyerW']:\n",
    "#         rename_value(df['Neighborhood'], val, 'low')\n",
    "#     for val in ['Crawfor', 'Edwards', 'Gilbert', 'NWAmes', 'NoRidge', 'SWISU', 'Somerst', 'StoneBr',\n",
    "#                 'Timber', 'Veenker']:\n",
    "#         rename_value(df['Neighborhood'], val, 'mid')\n",
    "#     for val in ['ClearCr', 'NridgHt']:\n",
    "#         rename_value(df['Neighborhood'], val, 'high')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to train a random forest model\n",
    "\n",
    "def random_forest_model(df_processed, target):\n",
    "    print(\"Building random forest model...\")\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df_processed, target, test_size=0.2, random_state=23)\n",
    "    \n",
    "    parameters= {\n",
    "        'max_depth':[12],\n",
    "        'min_samples_leaf':[2],\n",
    "        'min_samples_split':[2],\n",
    "        'n_estimators':[150, 300, 500],\n",
    "        'bootstrap':[True]\n",
    "    }\n",
    "    forest = RandomForestRegressor(n_jobs=4, random_state=42)\n",
    "    optimized_model = GridSearchCV(forest, parameters)\n",
    "    \n",
    "    optimized_model.fit(X_train, y_train)\n",
    "    \n",
    "    print(\"The model's R2 score is: {}\".format(optimized_model.best_estimator_.score(X_test, y_test)))\n",
    "    return optimized_model.best_estimator_\n",
    "\n",
    "# returns rf model object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to train an XGBoost model\n",
    "\n",
    "def xgboost_model(df_processed, target):\n",
    "    \n",
    "    print(\"Building xgboost model...\")\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df_processed, target, test_size=0.2, random_state=23)\n",
    "    \n",
    "    parameters = {\n",
    "        'learning_rate':[0.1, 0.3],\n",
    "        'gamma':[0, 100],\n",
    "        'max_depth':[3, 5, 7],\n",
    "        'n_estimators':[300, 500]\n",
    "    }\n",
    "    \n",
    "    xgbc = xgb.XGBRegressor(n_jobs=4, random_state=42)\n",
    "    optimized_model = GridSearchCV(xgbc, parameters)\n",
    "    \n",
    "    optimized_model.fit(X_train, y_train)\n",
    "    \n",
    "    predictions = optimized_model.best_estimator_.predict(X_test)\n",
    "    xgb_score = r2_score(y_test, predictions)\n",
    "    \n",
    "    print(\"The model's R2 score is: {}\".format(xgb_score))\n",
    "    return optimized_model.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to obtain feature importances from a random forest model\n",
    "\n",
    "def get_rf_feature_importances(rf_model, df):\n",
    "    print(\"Gathering feature importances...\")\n",
    "    importances = pd.Series(data=rf_model.feature_importances_, index=df.columns)\n",
    "    importances.sort_values(ascending=False, inplace=True)\n",
    "    print(\"Featue importances obtained.\")\n",
    "    return importances\n",
    "\n",
    "# returns series of feature importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_dataframes(df1, df2):\n",
    "    df_combined = pd.concat([df1, df2], axis=1, sort=False)\n",
    "    return df_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_predictions(df_test, model):\n",
    "    print(\"Generating predictions using the trained model...\")\n",
    "    numerical_features, categorical_features = get_numerical_categorical_lists(df_test)\n",
    "    df_num_imputed, df_cat_imputed = impute_features(df_test[numerical_features].copy(), \n",
    "                                                     df_test[categorical_features].copy())\n",
    "    df_combined_imputed = pd.concat([df_num_imputed, df_cat_imputed], axis=1, sort=False)\n",
    "    prediction = model.predict(df_combined_imputed)\n",
    "    print(\"Predictions complete.\")\n",
    "    return prediction\n",
    "\n",
    "# returns a prediction array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to output submission file\n",
    "\n",
    "def create_submission(df_test, prediction):\n",
    "    print(\"Generating submission file...\")\n",
    "    df_out = pd.DataFrame(data=prediction, columns=['SalePrice'], index=df_test.Id)\n",
    "    df_out.to_csv('submission_v1.csv')\n",
    "    print(\"Submission file is ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Main Code Below ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def run_model(model):\n",
    "    \n",
    "#     train_data, test_data = get_data()\n",
    "#     target = train_data['SalePrice']\n",
    "#     train_data = remove_null_columns(train_data)\n",
    "#     numerical_features, categorical_features = get_feature_lists(train_data)\n",
    "    \n",
    "#     df_num_train, df_cat_train = impute_features(train_data[numerical_features].copy(), train_data[categorical_features].copy())\n",
    "#     df_num_test, df_cat_test = impute_features(test_data[numerical_features].copy(), test_data[categorical_features].copy())\n",
    "    \n",
    "#     common_categories = prune_categorical_features(df_cat_train, df_cat_test)\n",
    "    \n",
    "#     df_train = combine_dataframes(df_num_train, df_cat_train[common_categories])\n",
    "#     df_test = combine_dataframes(df_num_test, df_cat_test[common_categories])\n",
    "    \n",
    "#     df_train = feature_engineering(df_train.copy())\n",
    "#     df_test = feature_engineering(df_test.copy())\n",
    "    \n",
    "#     predictions = model.predict(df_test)\n",
    "    \n",
    "#     create_submission(test_data, predictions)\n",
    "    \n",
    "#     return model, df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model, df_train = run_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_importances = get_rf_feature_importances(df=df_train, rf_model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
