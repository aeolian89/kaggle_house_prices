{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost Model Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------- #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import functions from model_functions notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i model_functions.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model():\n",
    "    \n",
    "    train_data, test_data = get_data()\n",
    "    \n",
    "    #modification: remove outliers for 'SalePrice' vs 'GrLivArea'\n",
    "    train_data.drop(train_data[(train_data['GrLivArea']>4000) & (train_data['SalePrice']<300000)].index)\n",
    "    \n",
    "    target = train_data['SalePrice'].apply(lambda x: np.log(x))\n",
    "    train_data = remove_null_columns(train_data)\n",
    "    numerical_features, categorical_features = get_feature_lists(train_data)\n",
    "    \n",
    "    df_num_train, df_cat_train = impute_features(train_data[numerical_features].copy(), train_data[categorical_features].copy())\n",
    "    df_num_test, df_cat_test = impute_features(test_data[numerical_features].copy(), test_data[categorical_features].copy())\n",
    "    \n",
    "    common_categories = prune_categorical_features(df_cat_train, df_cat_test)\n",
    "    \n",
    "    df_train = combine_dataframes(df_num_train, df_cat_train[common_categories])\n",
    "    df_test = combine_dataframes(df_num_test, df_cat_test[common_categories])\n",
    "    \n",
    "    df_train = feature_engineering(df_train.copy())\n",
    "    df_test = feature_engineering(df_test.copy())\n",
    "    \n",
    "    # Change the line below to substitute different models\n",
    "    model = xgboost_model(df_train, target=target)\n",
    "    \n",
    "    predictions = np.exp(model.predict(df_test))\n",
    "    \n",
    "    create_submission(test_data, predictions)\n",
    "    \n",
    "    return model, df_train, df_test, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grabbing train data from 'data/train.csv'...\n",
      "Grabbing test data from 'data/test.csv'...\n",
      "Data successfully loaded.\n",
      "Removing columns that are >50% null...\n",
      "4 columns were removed.\n",
      "Obtaining feature column names...\n",
      "34 numeric features obtained; 41 categorical features obtained\n",
      "Imputing data...\n",
      "Imputation complete.\n",
      "There are now 34 numerical features and 177 categorical features.\n",
      "Imputing data...\n",
      "Imputation complete.\n",
      "There are now 34 numerical features and 172 categorical features.\n",
      "Starting feature engineering...\n",
      "Feature engineering: transforming years to time since...\n",
      "Feature engineering: log transform of relevant numerical features...\n",
      "Feature engineering complete.\n",
      "Starting feature engineering...\n",
      "Feature engineering: transforming years to time since...\n",
      "Feature engineering: log transform of relevant numerical features...\n",
      "Feature engineering complete.\n",
      "Building xgboost model...\n",
      "The model's R2 score is: 0.9111948388306389\n",
      "Generating submission file...\n",
      "Submission file is ready.\n"
     ]
    }
   ],
   "source": [
    "optimal_model, df_train, df_test, predictions = run_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gathering feature importances...\n",
      "Featue importances obtained.\n"
     ]
    }
   ],
   "source": [
    "feature_importances = get_rf_feature_importances(df=df_train, rf_model=optimal_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LotArea                 0.064962\n",
       "LotFrontage             0.058824\n",
       "BsmtUnfSF               0.047059\n",
       "GrLivArea               0.045524\n",
       "OverallQual             0.042967\n",
       "HouseSFScore            0.040921\n",
       "BsmtFinSF1              0.036317\n",
       "GarageArea              0.030691\n",
       "PorchScore              0.028133\n",
       "BsmtIncompleteRatio     0.027621\n",
       "2ndFlrSF                0.026598\n",
       "GarageYrBlt             0.026598\n",
       "MasVnrArea              0.026598\n",
       "overallScore            0.024041\n",
       "WoodDeckSF              0.023529\n",
       "1stFlrSF                0.021483\n",
       "YearBuilt               0.019437\n",
       "OverallCond             0.018926\n",
       "ageScore                0.018926\n",
       "TotalBsmtSF             0.016368\n",
       "YearRemodAdd            0.013299\n",
       "BathScore               0.012276\n",
       "Neighborhood_StoneBr    0.012276\n",
       "OpenPorchSF             0.011765\n",
       "YrSold                  0.011253\n",
       "BsmtFinSF2              0.009719\n",
       "Neighborhood_Crawfor    0.009207\n",
       "ScreenPorch             0.008696\n",
       "Functional_NonTyp       0.008696\n",
       "Neighborhood_Somerst    0.008696\n",
       "dtype: float32"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importances[0:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LotArea',\n",
       " 'LotFrontage',\n",
       " 'BsmtUnfSF',\n",
       " 'GrLivArea',\n",
       " 'OverallQual',\n",
       " 'HouseSFScore',\n",
       " 'BsmtFinSF1',\n",
       " 'GarageArea',\n",
       " 'PorchScore',\n",
       " 'BsmtIncompleteRatio',\n",
       " '2ndFlrSF',\n",
       " 'GarageYrBlt',\n",
       " 'MasVnrArea',\n",
       " 'overallScore',\n",
       " 'WoodDeckSF',\n",
       " '1stFlrSF',\n",
       " 'YearBuilt',\n",
       " 'OverallCond',\n",
       " 'ageScore',\n",
       " 'TotalBsmtSF',\n",
       " 'YearRemodAdd',\n",
       " 'BathScore',\n",
       " 'Neighborhood_StoneBr',\n",
       " 'OpenPorchSF',\n",
       " 'YrSold',\n",
       " 'BsmtFinSF2',\n",
       " 'Neighborhood_Crawfor',\n",
       " 'ScreenPorch',\n",
       " 'Functional_NonTyp',\n",
       " 'Neighborhood_Somerst']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(feature_importances[0:30].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tinkering with using xgboost output as input to other models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grabbing train data from 'data/train.csv'...\n",
      "Grabbing test data from 'data/test.csv'...\n",
      "Data successfully loaded.\n"
     ]
    }
   ],
   "source": [
    "raw_train, raw_test = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_predictions = pd.Series(optimal_model.predict(df_train), index=df_train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_predictions = pd.Series(optimal_model.predict(df_test), index=df_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_train = pd.DataFrame(training_predictions, columns=['xgb_influence'], index=df_train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_test = pd.DataFrame(testing_predictions, columns=['xgb_influence'], index=df_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_train.to_csv('xgb_influence_train.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_test.to_csv('xgb_influence_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
